<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Building Deep Learning Models • DeepPatientLevelPrediction</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Building Deep Learning Models">
<meta name="robots" content="noindex">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">DeepPatientLevelPrediction</a>

    <small class="nav-text text-danger me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">2.2.0.9999</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../index.html"><span class="fa fa-home fa-lg"></span></a></li>
<li class="nav-item"><a class="nav-link" href="../articles/Installing.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../articles/FirstModel.html">My first deep learning model</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/BuildingDeepModels.html">Building Deep Learning Models</a></li>
    <li><a class="dropdown-item" href="../articles/FirstModel.html">Developing your first DeepPLP model</a></li>
    <li><a class="dropdown-item" href="../articles/Installing.html">DeepPatientLevelPrediction Installation Guide</a></li>
    <li><a class="dropdown-item" href="../articles/TransferLearning.html">How to use DeepPatientLevelPrediction for Transfer Learning</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><a class="external-link nav-link" href="https://ohdsi.github.io/Hades"><img src='https://ohdsi.github.io/Hades/images/hadesMini.png' width=80 height=17 style='vertical-align: top;'></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/OHDSI/DeepPatientLevelPrediction"><span class="fa fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Building Deep Learning Models</h1>
                        <h4 data-toc-skip class="author">Jenna Reps,
Egill Fridgeirsson, Chungsoo Kim, Henrik John, Seng Chan You, Xiaoyong
Pan</h4>
            
            <h4 data-toc-skip class="date">2025-09-21</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/OHDSI/DeepPatientLevelPrediction/blob/develop/vignettes/BuildingDeepModels.Rmd" class="external-link"><code>vignettes/BuildingDeepModels.Rmd</code></a></small>
      <div class="d-none name"><code>BuildingDeepModels.Rmd</code></div>
    </div>

    
    
<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{Building Deep Learning Models}
-->
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<div class="section level3">
<h3 id="deeppatientlevelprediction">DeepPatientLevelPrediction<a class="anchor" aria-label="anchor" href="#deeppatientlevelprediction"></a>
</h3>
<p>Patient level prediction aims to use historic data to learn a
function between an input (a patient’s features such as
age/gender/comorbidities at index) and an output (whether the patient
experienced an outcome during some time-at-risk). Deep learning is
example of the the current state-of-the-art classifiers that can be
implemented to learn the function between inputs and outputs.</p>
<p>Deep Learning models are widely used to automatically learn
high-level feature representations from the data, and have achieved
remarkable results in image processing, speech recognition and
computational biology. Recently, interesting results have been shown
using large observational healthcare data (e.g., electronic healthcare
data or claims data), but more extensive research is needed to assess
the power of Deep Learning in this domain.</p>
<p>This vignette describes how you can use the Observational Health Data
Sciences and Informatics (OHDSI) <a href="http://github.com/OHDSI/PatientLevelPrediction" class="external-link"><code>PatientLevelPrediction</code></a>
package and <a href="http://github.com/OHDSI/DeepPatientLevelPrediction" class="external-link"><code>DeepPatientLevelPrediction</code></a>
package to build Deep Learning models. This vignette assumes you have
read and are comfortable with building patient level prediction models
as described in the <a href="https://ohdsi.github.io/PatientLevelPrediction/articles/BuildingPredictiveModels.html" class="external-link"><code>BuildingPredictiveModels</code>
vignette</a>. Furthermore, this vignette assumes you are familiar with
Deep Learning methods.</p>
</div>
<div class="section level3">
<h3 id="background">Background<a class="anchor" aria-label="anchor" href="#background"></a>
</h3>
<p>Deep Learning models are build by stacking an often large number of
neural network layers that perform feature engineering steps, e.g
embedding, and are collapsed in a final linear layer (equivalent to
logistic regression). These algorithms need a lot of data to converge to
a good representation, but currently the sizes of the large
observational healthcare databases are growing fast which would make
Deep Learning an interesting approach to test within OHDSI’s <a href="https://academic.oup.com/jamia/article/25/8/969/4989437" class="external-link">Patient-Level
Prediction Framework</a>. The current implementation allows us to
perform research at scale on the value and limitations of Deep Learning
using observational healthcare data.</p>
<p>In the package we use <code>pytorch</code> through the
<code>reticulate</code> package.</p>
<p>Many network architectures have recently been proposed and we have
implemented a number of them, however, this list will grow in the near
future. It is important to understand that some of these architectures
require a 2D data matrix, i.e. |patient|x|feature|, and others use a 3D
data matrix |patient|x|feature|x|time|. The <a href="www.github.com%5Cohdsi%5CFeatureExtraction">FeatureExtraction
Package</a> has been extended to enable the extraction of both data
formats as will be described with examples below.</p>
<p>Note that training Deep Learning models is computationally intensive,
our implementation therefore supports both GPU and CPU. A GPU is highly
recommended and neccesary for most models for Deep Learning!</p>
</div>
<div class="section level3">
<h3 id="requirements">Requirements<a class="anchor" aria-label="anchor" href="#requirements"></a>
</h3>
<p>Full details about the package requirements and instructions on
installing the package can be found <a href="https://ohdsi.github.io/DeepPatientLevelPrediction/articles/Installing.html" class="external-link">here</a>.</p>
</div>
<div class="section level3">
<h3 id="integration-with-patientlevelprediction">Integration with PatientLevelPrediction<a class="anchor" aria-label="anchor" href="#integration-with-patientlevelprediction"></a>
</h3>
<p>The <code>DeepPatientLevelPrediction</code> package provides
additional model settings that can be used within the
<code>PatientLevelPrediction</code> package <code>runPlp()</code> and
<code>runMultiplePlp()</code> functions. To use both packages you first
need to pick the deep learning architecture you wish to fit (see below)
and then you specify this as the modelSettings inside
<code>runPlp()</code>.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># load the data</span></span>
<span><span class="va">plpData</span> <span class="op">&lt;-</span> <span class="fu">PatientLevelPrediction</span><span class="fu">::</span><span class="fu"><a href="https://ohdsi.github.io/PatientLevelPrediction/reference/loadPlpData.html" class="external-link">loadPlpData</a></span><span class="op">(</span><span class="st">'locationOfData'</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># pick the set&lt;Model&gt; from  DeepPatientLevelPrediction</span></span>
<span><span class="va">deepLearningModel</span> <span class="op">&lt;-</span> <span class="fu">DeepPatientLevelPrediction</span><span class="fu">::</span><span class="fu"><a href="../reference/setDefaultResNet.html">setDefaultResNet</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># use PatientLevelPrediction to fit model</span></span>
<span><span class="va">deepLearningResult</span> <span class="op">&lt;-</span> <span class="fu">PatientLevelPrediction</span><span class="fu">::</span><span class="fu"><a href="https://ohdsi.github.io/PatientLevelPrediction/reference/runPlp.html" class="external-link">runPlp</a></span><span class="op">(</span></span>
<span>    plpData <span class="op">=</span> <span class="va">plpData</span>, </span>
<span>    outcomeId <span class="op">=</span> <span class="fl">1230</span>, </span>
<span>    modelSettings <span class="op">=</span> <span class="va">deepLearningModel</span>,</span>
<span>    analysisId <span class="op">=</span> <span class="st">'resNetTorch'</span>, </span>
<span>    <span class="va">...</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="non-temporal-architectures">Non-Temporal Architectures<a class="anchor" aria-label="anchor" href="#non-temporal-architectures"></a>
</h2>
<p>We implemented the following non-temporal (2D data matrix)
architectures:</p>
<div class="section level3">
<h3 id="simple-multilayerperceptron">Simple MultiLayerPerceptron<a class="anchor" aria-label="anchor" href="#simple-multilayerperceptron"></a>
</h3>
<div class="section level4">
<h4 id="overall-concept">Overall concept<a class="anchor" aria-label="anchor" href="#overall-concept"></a>
</h4>
<p>A multilayer perceptron (MLP) model is a directed graph consisting of
an input layer, one or more hidden layers and an output layer. The model
takes in the input feature values and feeds these forward through the
graph to determine the output class. A process known as
‘backpropagation’ is used to train the model. Backpropagation requires
some ground truth and involves automatically calculating the derivative
of the model parameters with respect to the the error between the
model’s predictions and ground truth. Then the model learns how to
adjust the model’s parameters to reduce the error.</p>
</div>
<div class="section level4">
<h4 id="example">Example<a class="anchor" aria-label="anchor" href="#example"></a>
</h4>
<div class="section level5">
<h5 id="set-function">Set Function<a class="anchor" aria-label="anchor" href="#set-function"></a>
</h5>
<p>To use the package to fit a MLP model you can use the
<code><a href="../reference/setMultiLayerPerceptron.html">setMultiLayerPerceptron()</a></code> function to specify the
hyper-parameter settings for the MLP.</p>
</div>
<div class="section level5">
<h5 id="inputs">Inputs<a class="anchor" aria-label="anchor" href="#inputs"></a>
</h5>
<p>The <code>numLayers</code> and <code>sizeHidden</code> inputs define
the network topology via the number of layers and neurons in the
network’s hidden layers.</p>
<p>The <code>dropout</code> input specifies the probability that a layer
randomly sets some inputs to 0 at each step during training time. A
value of <code>0.2</code> means that 20% of the layers inputs will be
set to 0. This is used to reduce overfitting.</p>
<p>The <code>sizeEmbedding</code> input specifies the size of the
embedding used. The first layer is an embedding layer which converts
each sparse feature to a dense learned vector. An embedding is a lower
dimensional projection of the features where distance between points is
a measure of similarity.</p>
<p>The <code>weightDecay</code> input corresponds to the weight decay in
the objective function. During model fitting the aim is to minimize the
objective function. The objective function is made up of the prediction
error (the difference between the prediction vs the truth) plus the
square of the weights multiplied by the weight decay. The larger the
weight decay, the more you penalize having large weights. If you set the
weight decay too large, the model will never fit well enough, if you set
it too low, you need to be careful of overfitting (so try to stop model
fitting earlier).</p>
<p>The <code>learningRate</code> input is the learning rate which is a
hyperparameter that controls how much to change the model in response to
the estimated error each time the model weights are updated. The smaller
the <code>learningRate</code> the longer it will take to fit the model
and the model weights may get stuck, but if the
<code>learningRate</code> is too large, the weights may sub-optimally
converge too fast.</p>
<p>The <code>seed</code> lets the user use the same random
initialization of the network’s weights as a previous run.</p>
<p>The <code>hyperParamSearch</code> chooses the strategy to find the
best hyperparameters. Currently a random search and grid search are
supported. Grid search searches every possible combination of
hyperparameters while random search samples randomly from the
combinations. Since neural networks can be very flexible and have many
hyperparameter combinations it’s almost never feasible to do a full grid
search unless the network is really small.</p>
<p>The <code>randomSample</code> chooses how many random samples to
use.</p>
<p>The <code>device</code> specifies what device to use. Either
<code>cpu</code> or <code>cuda</code>. Or if you have many GPU’s
<code>cuda:x</code> where x is the gpu number as seen in
<code>nvidia-smi</code>.</p>
<p>The <code>batchSize</code> corresponds to the number of data points
(patients) used per iteration to estimate the network error during model
fitting.</p>
<p>The <code>epochs</code> corresponds to how many time to run through
the entire training data while fitting the model.</p>
</div>
<div class="section level5">
<h5 id="example-code">Example Code<a class="anchor" aria-label="anchor" href="#example-code"></a>
</h5>
<p>For example, the following code will try 10 different network
configurations sampled from the possible combinations given and pick the
one that obtains the greatest AUROC via cross validation in the training
data and then fit the model with that configuration using all the
training data. The standard output of <code>runPlp()</code> will be
returned - this contains the MLP model along with the performance
details and settings. Note that all possible combinations are
2<em>2</em>2*2 or 16 but specify <code>randomSample=10</code> to only
try 10 of those.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">modelSettings</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/setMultiLayerPerceptron.html">setMultiLayerPerceptron</a></span><span class="op">(</span></span>
<span>  numLayers <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3L</span>, <span class="fl">5L</span><span class="op">)</span>,</span>
<span>  sizeHidden <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">64L</span>, <span class="fl">128L</span><span class="op">)</span>, </span>
<span>  dropout <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.2</span><span class="op">)</span>,</span>
<span>  sizeEmbedding <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">32L</span>, <span class="fl">64L</span><span class="op">)</span>,</span>
<span>  estimatorSettings <span class="op">=</span> <span class="fu"><a href="../reference/setEstimator.html">setEstimator</a></span><span class="op">(</span></span>
<span>    learningRate <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1e-3</span>, <span class="fl">1e-4</span><span class="op">)</span>,</span>
<span>    weightDecay <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1e-5</span><span class="op">)</span>,</span>
<span>    batchSize <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">128L</span><span class="op">)</span>,</span>
<span>    epochs<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">5L</span><span class="op">)</span>,</span>
<span>    seed<span class="op">=</span><span class="fl">12L</span></span>
<span>  <span class="op">)</span>,</span>
<span>  randomSample<span class="op">=</span><span class="fl">10L</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">mlpResult</span> <span class="op">&lt;-</span> <span class="fu">PatientLevelPrediction</span><span class="fu">::</span><span class="fu"><a href="https://ohdsi.github.io/PatientLevelPrediction/reference/runPlp.html" class="external-link">runPlp</a></span><span class="op">(</span></span>
<span>    plpData <span class="op">=</span> <span class="va">plpData</span>, </span>
<span>    outcomeId <span class="op">=</span> <span class="fl">3</span>, </span>
<span>    modelSettings <span class="op">=</span> <span class="va">modelSettings</span>,</span>
<span>    analysisId <span class="op">=</span> <span class="st">'MLP'</span>, </span>
<span>    analysisName <span class="op">=</span> <span class="st">'Testing Deep Learning'</span>, </span>
<span>    populationSettings <span class="op">=</span> <span class="va">populationSet</span>, </span>
<span>    splitSettings <span class="op">=</span> <span class="fu">PatientLevelPrediction</span><span class="fu">::</span><span class="fu"><a href="https://ohdsi.github.io/PatientLevelPrediction/reference/createDefaultSplitSetting.html" class="external-link">createDefaultSplitSetting</a></span><span class="op">(</span><span class="op">)</span>, </span>
<span>    preprocessSettings <span class="op">=</span> <span class="fu">PatientLevelPrediction</span><span class="fu">::</span><span class="fu"><a href="https://ohdsi.github.io/PatientLevelPrediction/reference/createPreprocessSettings.html" class="external-link">createPreprocessSettings</a></span><span class="op">(</span><span class="op">)</span>, </span>
<span>    executeSettings <span class="op">=</span> <span class="fu">PatientLevelPrediction</span><span class="fu">::</span><span class="fu"><a href="https://ohdsi.github.io/PatientLevelPrediction/reference/createExecuteSettings.html" class="external-link">createExecuteSettings</a></span><span class="op">(</span></span>
<span>      runSplitData <span class="op">=</span> <span class="cn">TRUE</span>, </span>
<span>      runSampleData <span class="op">=</span> <span class="cn">FALSE</span>, </span>
<span>      runFeatureEngineering <span class="op">=</span> <span class="cn">FALSE</span>, </span>
<span>      runPreprocessData <span class="op">=</span> <span class="cn">TRUE</span>, </span>
<span>      runModelDevelopment <span class="op">=</span> <span class="cn">TRUE</span>, </span>
<span>      runCovariateSummary <span class="op">=</span> <span class="cn">FALSE</span></span>
<span>    <span class="op">)</span>, </span>
<span>    saveDirectory <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/file.path.html" class="external-link">file.path</a></span><span class="op">(</span><span class="va">testLoc</span>, <span class="st">'DeepNNTorch'</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="resnet">ResNet<a class="anchor" aria-label="anchor" href="#resnet"></a>
</h3>
<div class="section level4">
<h4 id="overall-concept-1">Overall concept<a class="anchor" aria-label="anchor" href="#overall-concept-1"></a>
</h4>
<p>Deep learning models are often trained via a process known as
gradient descent. During this process the network weights are updated
based on the gradient of the error function for the current weights.
However, as the number of layers in the network increase, there is a
greater chance of experiencing an issue known vanishing or exploding
gradients. The vanishing or exploding gradient is when the gradient goes
to 0 or infinity, which negatively impacts the model fitting.</p>
<p>The residual network (ResNet) was introduced to address the vanishing
or exploding gradient issue. It works by adding connections between
non-adjacent layers, termed a ‘skip connection’.</p>
<p>The ResNet calculates embeddings for every feature and then averages
them to compute an embedding per patient.</p>
<p>Our implementation of a ResNet for tabular data is based on <a href="https://arxiv.org/abs/2106.11959" class="external-link">this paper</a>.</p>
</div>
<div class="section level4">
<h4 id="example-1">Example<a class="anchor" aria-label="anchor" href="#example-1"></a>
</h4>
<div class="section level5">
<h5 id="set-function-1">Set Function<a class="anchor" aria-label="anchor" href="#set-function-1"></a>
</h5>
<p>To use the package to fit a ResNet model you can use the
<code><a href="../reference/setResNet.html">setResNet()</a></code> function to specify the hyperparameter settings
for the network.</p>
</div>
<div class="section level5">
<h5 id="inputs-1">Inputs<a class="anchor" aria-label="anchor" href="#inputs-1"></a>
</h5>
<div class="section level6">
<h6 id="model-inputs">Model inputs:<a class="anchor" aria-label="anchor" href="#model-inputs"></a>
</h6>
<p><code>numLayers</code>: How many layers to use in the model.</p>
<p><code>sizeHidden</code>: How many neurons in each hidden layer</p>
<p><code>hiddenFactor</code>: How much to increase number of neurons in
each layer (see paper)</p>
<p><code>residualDropout</code> and<code>hiddenDropout</code> : How much
dropout to apply in hidden layer or residual connection</p>
<p><code>sizeEmbedding</code> : The size of the initial embedding
layer</p>
</div>
<div class="section level6">
<h6 id="estimator-inputs">Estimator inputs:<a class="anchor" aria-label="anchor" href="#estimator-inputs"></a>
</h6>
<p><code>weightDecay</code> : How much weight decay to apply, which
penalizes bigger weights</p>
<p><code>learningRate</code> : Which learning rate to use</p>
<p><code>seed</code> : seed for weight initialization</p>
<p><code>device</code> : Which device to use, such as a <code>cpu</code>
or a <code>gpu</code></p>
<p><code>batchSize</code> : Size of batch of data used per iteration
during training</p>
<p><code>epochs</code> : How many runs through the data</p>
</div>
<div class="section level6">
<h6 id="hyperparameter-tuning-inputs">Hyperparameter tuning inputs:<a class="anchor" aria-label="anchor" href="#hyperparameter-tuning-inputs"></a>
</h6>
<p><code>hyperParamSearch</code> : Which type of hyperparameter search
to use, either random sampling or exhaustive (grid) search</p>
<p><code>randomSample</code>: If doing a random search for
hyperparameters, how many random samples to use</p>
<p><code>randomSampleSeed</code>: Seed to make hyperparameter search
reproducible</p>
</div>
</div>
<div class="section level5">
<h5 id="example-code-1">Example Code<a class="anchor" aria-label="anchor" href="#example-code-1"></a>
</h5>
<p>For example, the following code will fit a two layer ResNet where
each layer has 32 neurons which increases by a factor of two before
decreasing again (hiddenFactor). 10% of inputs to each layer and
residual connection within the layer are randomly zeroed during training
but not testing.The embedding layer has 32 neurons. Learning rate of
3e-4 with weight decay of 1e-6 is used for the optimizer. No
hyperparameter search is done since each input only includes one
option.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">resset</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/setResNet.html">setResNet</a></span><span class="op">(</span></span>
<span>  numLayers <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2L</span><span class="op">)</span>, </span>
<span>  sizeHidden <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">32L</span><span class="op">)</span>,</span>
<span>  hiddenFactor <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2L</span><span class="op">)</span>,</span>
<span>  residualDropout <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.1</span><span class="op">)</span>, </span>
<span>  hiddenDropout <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.1</span><span class="op">)</span>,</span>
<span>  sizeEmbedding <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">32L</span><span class="op">)</span>,</span>
<span>  estimatorSettings <span class="op">=</span> <span class="fu"><a href="../reference/setEstimator.html">setEstimator</a></span><span class="op">(</span>learningRate <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3e-4</span><span class="op">)</span>,</span>
<span>                                   weightDecay <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1e-6</span><span class="op">)</span>,</span>
<span>                                   <span class="co">#device='cuda:0', # uncomment to use GPU</span></span>
<span>                                   batchSize <span class="op">=</span> <span class="fl">128L</span>, </span>
<span>                                   epochs <span class="op">=</span> <span class="fl">3L</span>,</span>
<span>                                   seed <span class="op">=</span> <span class="fl">42L</span><span class="op">)</span>,</span>
<span>  hyperParamSearch <span class="op">=</span> <span class="st">'random'</span>,</span>
<span>  randomSample <span class="op">=</span> <span class="fl">1</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">resResult</span> <span class="op">&lt;-</span> <span class="fu">PatientLevelPrediction</span><span class="fu">::</span><span class="fu"><a href="https://ohdsi.github.io/PatientLevelPrediction/reference/runPlp.html" class="external-link">runPlp</a></span><span class="op">(</span></span>
<span>    plpData <span class="op">=</span> <span class="va">plpData</span>, </span>
<span>    outcomeId <span class="op">=</span> <span class="fl">3</span>, </span>
<span>    modelSettings <span class="op">=</span> <span class="va">resset</span>,</span>
<span>    analysisId <span class="op">=</span> <span class="st">'ResNet'</span>, </span>
<span>    analysisName <span class="op">=</span> <span class="st">'Testing ResNet'</span>, </span>
<span>    populationSettings <span class="op">=</span> <span class="va">populationSet</span>, </span>
<span>    splitSettings <span class="op">=</span> <span class="fu">PatientLevelPrediction</span><span class="fu">::</span><span class="fu"><a href="https://ohdsi.github.io/PatientLevelPrediction/reference/createDefaultSplitSetting.html" class="external-link">createDefaultSplitSetting</a></span><span class="op">(</span><span class="op">)</span>, </span>
<span>    preprocessSettings <span class="op">=</span> <span class="fu">PatientLevelPrediction</span><span class="fu">::</span><span class="fu"><a href="https://ohdsi.github.io/PatientLevelPrediction/reference/createPreprocessSettings.html" class="external-link">createPreprocessSettings</a></span><span class="op">(</span><span class="op">)</span>, </span>
<span>    executeSettings <span class="op">=</span> <span class="fu">PatientLevelPrediction</span><span class="fu">::</span><span class="fu"><a href="https://ohdsi.github.io/PatientLevelPrediction/reference/createExecuteSettings.html" class="external-link">createExecuteSettings</a></span><span class="op">(</span></span>
<span>      runSplitData <span class="op">=</span> <span class="cn">TRUE</span>, </span>
<span>      runSampleData <span class="op">=</span> <span class="cn">FALSE</span>, </span>
<span>      runFeatureEngineering <span class="op">=</span> <span class="cn">FALSE</span>, </span>
<span>      runPreprocessData <span class="op">=</span> <span class="cn">TRUE</span>, </span>
<span>      runModelDevelopment <span class="op">=</span> <span class="cn">TRUE</span>, </span>
<span>      runCovariateSummary <span class="op">=</span> <span class="cn">FALSE</span></span>
<span>    <span class="op">)</span>, </span>
<span>    saveDirectory <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/file.path.html" class="external-link">file.path</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/getwd.html" class="external-link">getwd</a></span><span class="op">(</span><span class="op">)</span>, <span class="st">'ResNet'</span><span class="op">)</span> <span class="co"># change to save elsewhere</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="transformer">Transformer<a class="anchor" aria-label="anchor" href="#transformer"></a>
</h3>
<div class="section level4">
<h4 id="overall-concept-2">Overall concept<a class="anchor" aria-label="anchor" href="#overall-concept-2"></a>
</h4>
<p>Recently there has been a surge of models in natural language
processing and computer vision that utilize attention. This is a
technique where the model learns where to look and what to focus on in
the input data. This was first described in the attention is all you
need <a href="https://arxiv.org/abs/1706.03762" class="external-link">paper</a>. Here we have
used an implementation that has shown good performance on non-temporal
tabular data from this <a href="https://arxiv.org/abs/2106.11959" class="external-link">paper</a>.</p>
<p>This architecture is computationally expensive and scales badly with
longer sequence length. In this case the sequence is the amount of
features each patient has. Users need to be aware of how many features
they are feeding to the model since this will effect the computation
time heavily. This is something you control in
<code>FeatureExtraction</code> when you create your
<code>covariateSettings</code>.</p>
</div>
<div class="section level4">
<h4 id="examples">Examples<a class="anchor" aria-label="anchor" href="#examples"></a>
</h4>
<div class="section level5">
<h5 id="set-function-2">Set Function<a class="anchor" aria-label="anchor" href="#set-function-2"></a>
</h5>
<p>To use the package to fit a Transformer model you can use the
<code><a href="../reference/setTransformer.html">setTransformer()</a></code> function to specify the hyperparameter
settings for the network.</p>
</div>
<div class="section level5">
<h5 id="inputs-2">Inputs<a class="anchor" aria-label="anchor" href="#inputs-2"></a>
</h5>
<p>The training and hyperparameter tuning inputs are the same as for the
ResNet.</p>
<div class="section level6">
<h6 id="model-inputs-1">Model inputs:<a class="anchor" aria-label="anchor" href="#model-inputs-1"></a>
</h6>
<p><code>numBlocks</code> : How many Transformer blocks to use, each
block includes a self-attention layer and a feedforward block with two
linear layers.</p>
<p><code>dimToken</code> : Dimension of the embedding for each
feature.</p>
<p><code>dimOut</code> : Dimension of output, for binary problems this
is 1.</p>
<p><code>numHeads</code> : Number of attention heads for the
self-attention, <code>dimToken</code> needs to be divisible by
<code>numHeads</code>.</p>
<p><code>attDropout</code>, <code>ffnDropout</code> : How much dropout
to apply on attentions or feedforward block</p>
<p><code>dimHidden</code> : How many neurons in linear layers inside the
feedforward block</p>
</div>
</div>
<div class="section level5">
<h5 id="example-code-2">Example Code<a class="anchor" aria-label="anchor" href="#example-code-2"></a>
</h5>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">modelSettings</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/setTransformer.html">setTransformer</a></span><span class="op">(</span>numBlocks <span class="op">=</span> <span class="fl">3L</span>,</span>
<span>                                dimToken <span class="op">=</span> <span class="fl">32L</span>,</span>
<span>                                dimOut <span class="op">=</span> <span class="fl">1</span>, </span>
<span>                                numHeads <span class="op">=</span> <span class="fl">4L</span>,</span>
<span>                                attDropout <span class="op">=</span> <span class="fl">0.25</span>,</span>
<span>                                ffnDropout <span class="op">=</span> <span class="fl">0.25</span>,</span>
<span>                                dimHidden <span class="op">=</span> <span class="fl">128L</span>,</span>
<span>                                estimatorSettings <span class="op">=</span> <span class="fu"><a href="../reference/setEstimator.html">setEstimator</a></span><span class="op">(</span></span>
<span>                                  learningRate <span class="op">=</span> <span class="fl">3e-4</span>,</span>
<span>                                  weightDecay <span class="op">=</span> <span class="fl">1e-6</span>,</span>
<span>                                  batchSize <span class="op">=</span> <span class="fl">128L</span>,</span>
<span>                                  epochs <span class="op">=</span> <span class="fl">10L</span>,</span>
<span>                                  device <span class="op">=</span> <span class="st">'cpu'</span></span>
<span>                                <span class="op">)</span>,</span>
<span>                                randomSample<span class="op">=</span><span class="fl">1L</span><span class="op">)</span></span>
<span>                              </span>
<span></span>
<span></span>
<span><span class="va">TransformerResult</span> <span class="op">&lt;-</span> <span class="fu">PatientLevelPrediction</span><span class="fu">::</span><span class="fu"><a href="https://ohdsi.github.io/PatientLevelPrediction/reference/runPlp.html" class="external-link">runPlp</a></span><span class="op">(</span></span>
<span>    plpData <span class="op">=</span> <span class="va">plpData</span>, </span>
<span>    outcomeId <span class="op">=</span> <span class="fl">3</span>, </span>
<span>    modelSettings <span class="op">=</span> <span class="va">modelSettings</span>,</span>
<span>    analysisId <span class="op">=</span> <span class="st">'Transformer'</span>, </span>
<span>    analysisName <span class="op">=</span> <span class="st">'Testing transformer'</span>, </span>
<span>    populationSettings <span class="op">=</span> <span class="va">populationSet</span>, </span>
<span>    splitSettings <span class="op">=</span> <span class="fu">PatientLevelPrediction</span><span class="fu">::</span><span class="fu"><a href="https://ohdsi.github.io/PatientLevelPrediction/reference/createDefaultSplitSetting.html" class="external-link">createDefaultSplitSetting</a></span><span class="op">(</span><span class="op">)</span>, </span>
<span>    preprocessSettings <span class="op">=</span> <span class="fu">PatientLevelPrediction</span><span class="fu">::</span><span class="fu"><a href="https://ohdsi.github.io/PatientLevelPrediction/reference/createPreprocessSettings.html" class="external-link">createPreprocessSettings</a></span><span class="op">(</span><span class="op">)</span>, </span>
<span>    executeSettings <span class="op">=</span> <span class="fu">PatientLevelPrediction</span><span class="fu">::</span><span class="fu"><a href="https://ohdsi.github.io/PatientLevelPrediction/reference/createExecuteSettings.html" class="external-link">createExecuteSettings</a></span><span class="op">(</span></span>
<span>      runSplitData <span class="op">=</span> <span class="cn">TRUE</span>, </span>
<span>      runSampleData <span class="op">=</span> <span class="cn">FALSE</span>, </span>
<span>      runFeatureEngineering <span class="op">=</span> <span class="cn">FALSE</span>, </span>
<span>      runPreprocessData <span class="op">=</span> <span class="cn">TRUE</span>, </span>
<span>      runModelDevelopment <span class="op">=</span> <span class="cn">TRUE</span>, </span>
<span>      runCovariateSummary <span class="op">=</span> <span class="cn">FALSE</span></span>
<span>    <span class="op">)</span>, </span>
<span>    saveDirectory <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/file.path.html" class="external-link">file.path</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/getwd.html" class="external-link">getwd</a></span><span class="op">(</span><span class="op">)</span>, <span class="st">'Transformer'</span><span class="op">)</span> <span class="co"># change to save elsewhere</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
</div>
</div>
</div>
</div>
<div class="section level2">
<h2 id="acknowledgments">Acknowledgments<a class="anchor" aria-label="anchor" href="#acknowledgments"></a>
</h2>
<p>Considerable work has been dedicated to provide the
<code>DeepPatientLevelPrediction</code> package.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/citation.html" class="external-link">citation</a></span><span class="op">(</span><span class="st">"DeepPatientLevelPrediction"</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## To cite package 'DeepPatientLevelPrediction' in publications use:</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##   Fridgeirsson E, Reps J, Chan You S, Kim C, John H (2025).</span></span>
<span><span class="co">##   _DeepPatientLevelPrediction: Deep Learning for Patient Level</span></span>
<span><span class="co">##   Prediction Using Data in the OMOP Common Data Model_. R package</span></span>
<span><span class="co">##   version 2.2.0.9999,</span></span>
<span><span class="co">##   &lt;https://github.com/OHDSI/DeepPatientLevelPrediction&gt;.</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## A BibTeX entry for LaTeX users is</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##   @Manual{,</span></span>
<span><span class="co">##     title = {DeepPatientLevelPrediction: Deep Learning for Patient Level Prediction Using Data in the</span></span>
<span><span class="co">## OMOP Common Data Model},</span></span>
<span><span class="co">##     author = {Egill Fridgeirsson and Jenna Reps and Seng {Chan You} and Chungsoo Kim and Henrik John},</span></span>
<span><span class="co">##     year = {2025},</span></span>
<span><span class="co">##     note = {R package version 2.2.0.9999},</span></span>
<span><span class="co">##     url = {https://github.com/OHDSI/DeepPatientLevelPrediction},</span></span>
<span><span class="co">##   }</span></span></code></pre>
<p><strong>Please reference this paper if you use the PLP Package in
your work:</strong></p>
<p><a href="http://dx.doi.org/10.1093/jamia/ocy032" class="external-link">Reps JM, Schuemie
MJ, Suchard MA, Ryan PB, Rijnbeek PR. Design and implementation of a
standardized framework to generate and evaluate patient-level prediction
models using observational healthcare data. J Am Med Inform Assoc.
2018;25(8):969-975.</a></p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Egill Fridgeirsson, Jenna Reps, Seng Chan You, Chungsoo Kim, Henrik John.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
